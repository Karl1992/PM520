gamma.sim_1 <- function(lambda, m) {
iter <- 0
f <- function(x){
return(lambda^m * x^(m-1) * exp(-lambda * x) / gamma(m))
}
K <- 1
while (TRUE) {
X <- runif(1, 0, 20)
Y <- runif(1, 0, K)
iter <- iter + 1
if (Y < f(X)) return(c(X, iter))   # this does the rejection step
}
}
set.seed(1999)
n <- 10000        # number of replicates
g.1 <- mat.or.vec(n, 2)      # create somewhere to keep the answers
for (i in 1:n) g.1[i,] <- gamma.sim_1(1, 2)    # generate your 10000 gamma r.v.s
hist(g.1[,1], breaks=30, freq=F, xlab="x", ylab="pdf f(x)", main=c("theoretical and simulated gamma(1, 2) density", paste("iter =", sum(g.1[,2]))))
x <- seq(0, max(g.1[,1]), .1)
lines(x, dgamma(x, 2, 1))
gamma.sim <- function(lambda, m) {
# simulates a gamma(lambda, m) rv using rejection with an exp envelope
# assumes m > 1 and lambda > 0
# step 1: Define a function f(x)=lambda^m*x^(m-1)*exp(-lambda*x)/gamma(m)     --- the gamma density at x
## [ADD CODE HERE]
iter <- 0
f <- function(x){
return(lambda^m * x^(m-1) * exp(-lambda * x) / gamma(m))
}
# step 2: Define a function h(x)=lambda/m*exp(-lambda/m*x)     ---  the exponential density at x
## [ADD CODE HERE]
h <- function(x){
return(lambda / m * exp(- lambda / m * x))
}
# step 3: Define the value of k:  k=m^m*exp(1-m)/gamma(m)    --- in general. for m=2, lambda=1 we have k=4/e
## [ADD CODE HERE]
k <- m^m * exp(1 - m) / gamma(m)
while (TRUE) {    # keep sampling x's from h(x) and testing them until you accept one
X <- -log(runif(1))*m/lambda     # generate an x from h, the exponential density
# Now generate Y from Unif[0,Kh(x)] .....[ADD CODE HERE]
Y <- runif(1, 0, k * h(X))
# and then
iter <- iter + 1
if (Y < f(X)) return(c(X, iter))   # this does the rejection step
}
}
set.seed(1999)
n <- 10000        # number of replicates
g <- mat.or.vec(n, 2)      # create somewhere to keep the answers
for (i in 1:n) g[i,] <- gamma.sim(1, 2)    # generate your 10000 gamma r.v.s
hist(g[,1], breaks=20, freq=F, xlab="x", ylab="pdf f(x)", main=c("theoretical and simulated gamma(1, 2) density", paste("iter =", sum(g[,2]))))
x <- seq(0, max(g[,1]), .1)
lines(x, dgamma(x, 2, 1))
library(coda)
library(mcmc)
library(mvtnorm)
library(adaptMCMC)
set.seed(20190325)
t <- 100
mu.vector <- c(0,0)
variance_matrix <- cbind(c(1,0.9), c(0.9,1))
our.data <- rmvnorm(t, mu.vector, variance_matrix)
gibbs <- function(rou, n, initial){
iter <- 1
result <- mat.or.vec(n,2)
theta <- initial[t,1]
mu <- initial[t,2]
while (iter <= n){
thetaprime <- rnorm(1, rou * mu, 1 - rou^2)
muprime <- rnorm(1, rou * theta, 1 - rou^2)
theta <- thetaprime
mu <- muprime
result[iter,] <- c(theta, mu)
iter <- iter + 1
}
return(result)
}
gibbs_r1 <- gibbs(0.9, 100000, our.data)
gibbs_r2 <- gibbs(0.9, 100000, our.data)
gibbs_r3 <- gibbs(0.9, 100000, our.data)
corr_gibbs <- cor(gibbs_r1[,1], gibbs_r1[,2])
gibbs_r1 <- mcmc(gibbs_r1)
print(summary(gibbs_r1))
autocorr.plot(gibbs_r1, lag = 100, main = "Autocorrelation for gibbs_r1")
gibbs_r2 <- mcmc(gibbs_r2)
gibbs_r3 <- mcmc(gibbs_r3)
gibbs_r <- mcmc.list(list(gibbs_r1, gibbs_r2, gibbs_r3))
cat("\nGelman test results follow...")
print(gelman.diag(gibbs_r))
gelman.plot(gibbs_r, main = "Gelman plots")
plot(gibbs_r1, main = "Results for gibbs_r1")
plot(gibbs_r2, main = "Results for gibbs_r2")
acf(gibbs_r2)
do.MHMCMC<-function(number.of.iterations, current.mu, variance.matrix){
# define a vector to store the output of the MH-MCMC process
posterior.mu<-mat.or.vec(number.of.iterations,2)
for (i in 1:number.of.iterations){
#apply the proposal/transition-kernel to the current state to get the proposed new state
proposed.mu<-current.mu+runif(2,-0.2,0.2)
# calculate hastings ratio
# first we need the density of the data under the new and old values for the mean - note that we work with logs!
pdf.before<-sum(log(dmvnorm(our.data, mean=current.mu, sigma=variance.matrix)))
pdf.after<-sum(log(dmvnorm(our.data, mean=proposed.mu, sigma=variance.matrix)))
# our proposal kernel is symmetric, and uses uniform priors, so the Hastings ratio will be as follows:
hr<-exp(pdf.after-pdf.before)
# do we accept the transition?
p<-runif(1)
#browser()
if (p<hr){
# accept
current.mu<-proposed.mu
}else{
#reject - no need to do anything here
}
# store the current iteration
posterior.mu[i,]<-current.mu
}
return (posterior.mu)
}
# Let's run it three times to enable comparison of results
mh.draws1 <- do.MHMCMC(100000, mu.vector, variance_matrix)
mh.draws2 <- do.MHMCMC(100000, mu.vector, variance_matrix)
mh.draws3 <- do.MHMCMC(100000, mu.vector, variance_matrix)
corr_MH <- cor(mh.draws1[,1], mh.draws2[,2])
# Turn it into an mcmc object so that we can use the coda package
mh.draws1 <- mcmc(mh.draws1) # turn into an MCMC object
print(summary(mh.draws1))
autocorr.plot(mh.draws1,lag=100,main="Autocorrelation for mh.draws1")
# compare multiple chains
mh.draws2 <- mcmc(mh.draws2) # turn into an MCMC object
mh.draws3 <- mcmc(mh.draws3) # turn into an MCMC object
# combine them into what is known as an mcmc.list (a collection of mcmc outputs)
mh.list <- mcmc.list(list(mh.draws1, mh.draws2, mh.draws3))
# run the gelman test
cat("\nGelman test results follow...")
print(gelman.diag(mh.list))
gelman.plot(mh.list,main="Gelman plots")
# look at the output
plot(mh.draws1,main="Results for mh.draws1")
plot(mh.draws2,main="Result for mh.draws2")
acf(mh.draws2,main="Autocorrelation for mh.draws2")
adapt.log <- function(mu){
return(sum(log(dmvnorm(our.data, mean = mu, sigma = variance_matrix))))
}
adapt_1 <- MCMC(adapt.log, 100000, init = mu.vector, scale = c(0.2, 0.2), adapt = T, acc.rate = 0.25)
adapt_2 <- MCMC(adapt.log, 100000, init = mu.vector, scale = c(0.2, 0.2), adapt = T, acc.rate = 0.25)
adapt_3 <- MCMC(adapt.log, 100000, init = mu.vector, scale = c(0.2, 0.2), adapt = T, acc.rate = 0.25)
corr_adapt <- cor(adapt_1$samples[,1], adapt_1$samples[,2])
adapt_1_sample <- adapt_1$samples
adapt_2_sample <- adapt_2$samples
adapt_3_sample <- adapt_3$samples
adapt_1_sample <- mcmc(adapt_1_sample)
adapt_2_sample <- mcmc(adapt_2_sample)
adapt_3_sample <- mcmc(adapt_3_sample)
print(summary(adapt_1_sample))
autocorr.plot(adapt_1_sample,lag = 100, main = "Autocorrelation for adapt_1")
adapt_sample <- mcmc.list(list(adapt_1_sample, adapt_2_sample, adapt_3_sample))
cat("\nGelman test results follow...")
print(gelman.diag(adapt_sample))
gelman.plot(adapt_sample, main = "Gelman plots")
plot(adapt_1_sample, main = "Results for adapt_1")
plot(adapt_2_sample, main = "Results for adapt_2")
acf(adapt_2_sample)
}else{
Urn_G <- function(finalballamount, starting_ball, black_weight){
ball <- starting_ball # define the starting cituation
while(length(ball) < finalballamount){
pick <- sample(ball, 1, prob  = c(rep(1, length(ball)-1), black_weight)) # pick one ball from the urn
if (pick == "0"){ # 0 is black
ball <- ball[-which(ball == pick)] # pick the black ball
pick2 <- sample(1:length(ball), 1) # pick a ball from the remaining balls
ball[pick2] <- as.character(length(ball) + 1) # change the ball's color (since each iteration the length of ball will increase or remain the same, we'll never repeat the ball's color)
ball <- c(ball, pick) # put back the black ball
}else{
ball <- ball[-length(ball)]
ball <- c(ball, pick, "0") # else just add a ball with the picked color and keep the black ball at last of the row
}
}
return(ball)
}
NoReps <- 10000
Howmanycolorneeded <- 1
Maxweight <- 20
Noofballs <- 11
Acceptedweights <- rep(-9, NoReps)
for (i in 1:NoReps) {
HowManyColorsObserved<- -9
while (HowManyColorsObserved != Howmanycolorneeded) {
# Sample a weight, ThisWeight, for the mutation ball, from Unif(0,MaxWeight). Then...
ThisWeight <- sample(Maxweight,1)
Final_state <- Urn_G(Noofballs, c(1,1,0), ThisWeight) # simulate the urn using this weight
HowManyColorsObserved <- length(table(Final_state)) - 1
}
Acceptedweights[i]<-ThisWeight
}
hist(Acceptedweights, breaks = Maxweight)
set.seed(4321)
carrier<-rep(c(0,1), c(100,200))  # Make up an example with 100 carriers and 200 controls
null.y<-rnorm(300)   # our null data - here the value is independent of carrier status
alt.y<-rnorm(300, mean=carrier/2)   # our alternate data - here the mean depends on carrier status
t.test(null.y~carrier, var.equal=TRUE)
t.test(alt.y~carrier, var.equal=TRUE)
# Here's the observed difference in mean between the two groups for the null data
null.diff<-mean(null.y[carrier==1])-mean(null.y[carrier==0])
# And here's the observed difference in mean between the two groups for our alternate data
alt.diff<-mean(alt.y[carrier==1])-mean(alt.y[carrier==0])
one.test<-function(x,y){
xstar<-sample(x)  # samples without replacement - so this is producing a random permutation of x
m<-mean(y[xstar==1])-mean(y[xstar==0])  # then calcluate the difference in means between the two groups defined by the permuted x
return (m)
}
many.truenull <- replicate(1000, one.test(carrier, null.y))
many.falsenull <- replicate(1000, one.test(carrier, alt.y))
# plot histograms of the resulting distribution of difference of means
p1<-mean(abs(many.truenull) > abs(null.diff)) # the empirical p-value (for 2-sided test)
hist(many.truenull,main = c("Null p-value~",p1))
# add a line to it to indicate the 'observed' value
abline(v=null.diff, lwd=2, col="purple")
#text(x=-0.4,y=200,c("p-value=",mean/1000))
p2<-mean(abs(many.falsenull) > abs(alt.diff))  # the empirical p-value
hist(many.falsenull,main = c("Alt p-value~",p2))
abline(v=alt.diff, lwd=2, col="purple")
#install.packages("weights")
library(weights)
#install.packages("weights")
library(weights)
install.packages("weights")
# Example of how to do histograms with weights.
# This is from the docs for the "weights" R package
#install.packages("weights")
library(weights)
var1 <- c(1:100)   # a sequence from 1 to 100
wgt <- var1/mean(var1)
par(mfrow=c(2, 2)) # 2x2 plots
wtd.hist(var1,main="Weights all 1")  # by defaults, the weights are set to 1
wtd.hist(var1, weight=wgt,main="Weights given by wgt")  # Now uses the weights given by wgt
wtd.hist(var1, weight=var1,main="Weights given by var1")  # And now weights are given by var1
par(mfrow=c(1, 1)) # go back to a single plot
# Example of how to do histograms with weights.
# This is from the docs for the "weights" R package
#install.packages("weights")
library(weights)
var1 <- c(1:100)   # a sequence from 1 to 100
wgt <- var1/mean(var1)
par(mfrow=c(2, 2)) # 2x2 plots
wtd.hist(var1,main="Weights all 1")  # by defaults, the weights are set to 1
wtd.hist(var1, weight=wgt,main="Weights given by wgt")  # Now uses the weights given by wgt
wtd.hist(var1, weight=var1,main="Weights given by var1")  # And now weights are given by var1
par(mfrow=c(1, 1)) # go back to a single plot
hist(Acceptedweights, breaks = Maxweight)
